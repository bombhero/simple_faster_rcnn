{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 800, 800])\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 64, 800, 800])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 64, 800, 800])\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 64, 800, 800])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 64, 800, 800])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 64, 400, 400])\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 128, 400, 400])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 128, 400, 400])\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 128, 400, 400])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 128, 400, 400])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 128, 200, 200])\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 200, 200])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 200, 200])\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 200, 200])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 200, 200])\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 200, 200])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 256, 200, 200])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 256, 100, 100])\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 100, 100])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 100, 100])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 100, 100])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 100, 100])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 100, 100])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 100, 100])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 512, 50, 50])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 50, 50])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 50, 50])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 50, 50])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 50, 50])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 512, 50, 50])\n",
      "ReLU(inplace=True)\n",
      "torch.Size([1, 512, 50, 50])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 512, 25, 25])\n",
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# coding:utf8\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "img_tensor = torch.zeros((1, 3, 800, 800)).float()\n",
    "print(img_tensor.shape)\n",
    "# Out: torch.Size([1, 3, 800, 800])\n",
    "\n",
    "img_var = torch.autograd.Variable(img_tensor)\n",
    "\n",
    "model = torchvision.models.vgg16(pretrained=False)\n",
    "fe = list(model.features)\n",
    "# print(fe)  # length is 15\n",
    "\n",
    "req_features = []\n",
    "k = img_var.clone()\n",
    "for i in fe:\n",
    "    print(i)\n",
    "    k = i(k)\n",
    "    print(k.data.shape)\n",
    "    if k.size()[2] < 800//16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "print(len(req_features))  # 30\n",
    "print(out_channels)  # 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for f in req_features:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "faster_rcnn_fe_extractor = torch.nn.Sequential(*req_features)\n",
    "out_map = faster_rcnn_fe_extractor(img_var)\n",
    "print(out_map.size())\n",
    "# Out: torch.Size([1, 512, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "sub_sample = 16\n",
    "\n",
    "# 一个特征点对应原图片中的16*16个像素点区域\n",
    "fe_size = (800//16)\n",
    "# ctr_x， ctr_y: 每个特征点对应原图片区域的右下方坐标\n",
    "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size+1) * 16, 16)\n",
    "print(len(ctr_x))  # 共50*50个特征点，将原图片分割成50*50=2500个区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "# ctr: 每个特征点对应原图片区域的中心点\n",
    "ctr = dict()\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index] = [-1, -1]\n",
    "        ctr[index][1] = ctr_x[x] - 8\n",
    "        ctr[index][0] = ctr_y[y] - 8\n",
    "        index += 1\n",
    "# print ctr\n",
    "print(len(ctr))  # 将原图片分割成50*50=2500个区域的中心点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n",
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "# 初始化：每个区域有9个anchors候选框，每个候选框的坐标(y1, x1, y2, x2)\n",
    "anchors = np.zeros(((fe_size * fe_size * 9), 4))\n",
    "# (22500, 4)\n",
    "print(anchors.shape)\n",
    "index = 0\n",
    "# 将候选框的坐标赋值到anchors\n",
    "for c in ctr:\n",
    "    ctr_y, ctr_x = ctr[c]\n",
    "    for i in range(len(ratios)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            # anchor_scales 是针对特征图的，所以需要乘以下采样\"sub_sample\"\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1. / ratios[i])\n",
    "            anchors[index, 0] = ctr_y - h / 2.\n",
    "            anchors[index, 1] = ctr_x - w / 2.\n",
    "            anchors[index, 2] = ctr_y + h / 2.\n",
    "            anchors[index, 3] = ctr_x + w / 2.\n",
    "            index += 1\n",
    "# (22500, 4)\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2729d1df860>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_npy = img_tensor.numpy()\n",
    "img_npy = np.transpose(img_npy[0], (1, 2, 0)).astype(np.float32)\n",
    "img = Image.fromarray(np.uint8(img_npy))\n",
    "draw = ImageDraw.Draw(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2729d428550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for index in range(15000, 15009):\n",
    "# for index in range(len(anchors)):\n",
    "#     draw.rectangle([(anchors[index, 1], anchors[index, 0]), (anchors[index, 3], anchors[index, 2])],\n",
    "#                    outline=(255, 0, 0))\n",
    "\n",
    "# 假设 图片中的两个目标框\"ground-truth\"\n",
    "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32)  # [y1, x1, y2, x2] format\n",
    "draw.rectangle([(30, 20), (500, 400)], outline=(100, 255, 0))\n",
    "draw.rectangle([(400, 300), (600, 500)], outline=(100, 255, 0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "# 假设 图片中两个目标框分别对应的标签\n",
    "labels = np.asarray([6, 8], dtype=np.int8)  # 0 represents background\n",
    "\n",
    "# 去除坐标出界的边框，保留图片内的框——图片内框\n",
    "valid_anchor_index = np.where(\n",
    "       (anchors[:, 0] >= 0) &\n",
    "       (anchors[:, 1] >= 0) &\n",
    "       (anchors[:, 2] <= 800) &\n",
    "       (anchors[:, 3] <= 800)\n",
    "   )[0]  # 该函数返回数组中满足条件的index\n",
    "print(valid_anchor_index.shape)  # (8940,)，表明有8940个框满足条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "# 获取有效anchor（即边框都在图片内的anchor）的坐标\n",
    "valid_anchor_boxes = anchors[valid_anchor_index]\n",
    "print(valid_anchor_boxes.shape)  # (8940, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  30. 400. 500.]\n",
      " [300. 400. 500. 600.]]\n"
     ]
    }
   ],
   "source": [
    "# 计算有效anchor框\"valid_anchor_boxes\"与目标框\"bbox\"的IOU\n",
    "ious = np.empty((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
    "ious.fill(0)\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06811669, 0.        ],\n",
       "       [0.07083762, 0.        ],\n",
       "       [0.07083762, 0.        ],\n",
       "       [0.07083762, 0.        ],\n",
       "       [0.07083762, 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    ya1, xa1, ya2, xa2 = i\n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)  # anchor框面积\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2 - yb1) * (xb2 - xb1)  # 目标框面积\n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)  # anchor框和目标框的相交面积\n",
    "            iou = iter_area / (anchor_area + box_area - iter_area)  # IOU计算\n",
    "        else:\n",
    "            iou = 0.0\n",
    "        ious[num1, num2] = iou\n",
    "print(ious.shape)  # (8940, 2)  表示每个anchor框与所有目标框的IOU，这里所有的目标框共2个。\n",
    "ious[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 5620]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis=0)  # 找出每个目标框最大IOU的anchor框index，共2个\n",
    "print(gt_argmax_ious)  # 共2个，与图片内目标框数量一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68130493 0.61035156]\n"
     ]
    }
   ],
   "source": [
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]  # 获取每个目标框最大IOU的值，与gt_argmax_ious对应\n",
    "print(gt_max_ious)  # 共2个，与图片内目标框数量一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis=1)  # 找出每个anchor框最大IOU的目标框index，共8940个\n",
    "print(argmax_ious.shape)  # (8940,) 每个anchor框都会对应一个最大IOU的目标框\n",
    "max_ious = ious[np.arange(len(valid_anchor_index)), argmax_ious]  # 获取每个anchor框的最大IOU值， 与argmax_ious对应\n",
    "print(max_ious.shape)  # (8940,),每个anchor框内都会有一个最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n",
      "[  8.   8. 520. 520.]\n",
      "[  8.  24. 520. 536.]\n",
      "[248. 344. 504. 600.]\n",
      "[264. 344. 520. 600.]\n",
      "[280. 344. 536. 600.]\n",
      "[296. 344. 552. 600.]\n",
      "[248. 360. 504. 616.]\n",
      "[264. 360. 520. 616.]\n",
      "[280. 360. 536. 616.]\n",
      "[296. 360. 552. 616.]\n",
      "[248. 376. 504. 632.]\n",
      "[264. 376. 520. 632.]\n",
      "[280. 376. 536. 632.]\n",
      "[296. 376. 552. 632.]\n",
      "[248. 392. 504. 648.]\n",
      "[264. 392. 520. 648.]\n",
      "[280. 392. 536. 648.]\n",
      "[296. 392. 552. 648.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2729d54eb00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 疑问： ious == gt_max_ious， 有区分目标\n",
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]  # 根据上面获取的目标最大IOU值，获取等于该值的index\n",
    "print(gt_argmax_ious.shape)  # (18,) 共计18个\n",
    "for index in gt_argmax_ious:\n",
    "    print(valid_anchor_boxes[index, :])\n",
    "    draw.rectangle([(valid_anchor_boxes[index, 1], valid_anchor_boxes[index, 0]),\n",
    "                    (valid_anchor_boxes[index, 3], valid_anchor_boxes[index, 2])], outline=(255, 0, 0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "18\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "pos_iou_threshold = 0.7\n",
    "neg_iou_threshold = 0.3\n",
    "label = np.empty((len(valid_anchor_index), ), dtype=np.int32)\n",
    "label.fill(-1)\n",
    "print(label.shape)  # (8940,)\n",
    "label[max_ious < neg_iou_threshold] = 0  # anchor框内最大IOU值小于neg_iou_threshold，设为0\n",
    "label[gt_argmax_ious] = 1  # anchor框有全局最大IOU值，设为1\n",
    "label[max_ious >= pos_iou_threshold] = 1  # anchor框内最大IOU值大于等于pos_iou_threshold，设为1\n",
    "\n",
    "pos_ratio = 0.5\n",
    "n_sample = 256\n",
    "n_pos = pos_ratio * n_sample  # 正例样本数\n",
    "\n",
    "# 随机获取n_pos个正例，\n",
    "pos_index = np.where(label == 1)[0]\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
    "    label[disable_index] = -1\n",
    "\n",
    "n_neg = n_sample - np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1\n",
    "print(np.sum(label == 1))  # 18个正例\n",
    "print(np.sum(label == 0))  # 256-18=238个负例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " ...\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]]\n",
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "# 现在让我们用具有最大iou的ground truth对象为每个anchor box分配位置。\n",
    "# 注意，我们将为所有有效的anchor box分配anchor locs，而不考虑其标签，稍后在计算损失时，我们可以使用简单的过滤器删除它们。\n",
    "max_iou_bbox = bbox[argmax_ious]  # 有效anchor框对应的目标框坐标  (8940, 4)\n",
    "print(max_iou_bbox)\n",
    "print(max_iou_bbox.shape)  # (8940, 4)，共有8940个有效anchor框，每个anchor有坐标值（y1, x1, y2, x2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "# 有效anchor的中心点和宽高：ctr_x, ctr_y, width, height\n",
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
    "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
    "# 有效anchor对应目标框的中心点和宽高: base_ctr_x, base_ctr_y, base_width, base_height\n",
    "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
    "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
    "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width\n",
    "\n",
    "# 有效anchor转为目标框的系数（dy，dx是平移系数；dh，dw是缩放系数）\n",
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "# print anchor_locs\n",
    "print(anchor_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
